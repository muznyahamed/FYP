{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4653356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6cca931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_acceleration_data(csv_file, label, df):\n",
    "    # Read the CSV file in chunks of 250 rows\n",
    "    chunk_size = 250\n",
    "    columns_to_select = ['Linear Acceleration x (m/s^2)', 'Linear Acceleration y (m/s^2)', 'Linear Acceleration z (m/s^2)']\n",
    "\n",
    "    for chunk in pd.read_csv(csv_file,usecols=columns_to_select, chunksize=chunk_size):\n",
    "        if len(chunk) < chunk_size:\n",
    "            break\n",
    "        # Select the first 250 columns\n",
    "        selected_columns = chunk.iloc[:, :250]\n",
    "        \n",
    "        # Reshape the selected columns into a 3-dimensional array\n",
    "        acceleration_data = selected_columns.values\n",
    "\n",
    "        \n",
    "        # Create a DataFrame for the acceleration data\n",
    "        acceleration_data = selected_columns.values.reshape(-1, 3, 250)\n",
    "        acceleration_df = pd.DataFrame({'Acceleration': [acceleration_data]})\n",
    "\n",
    "        \n",
    "        # Create a DataFrame for the label column\n",
    "        label_df = pd.DataFrame({'Label': [label] * len(acceleration_df)})\n",
    "        \n",
    "        # Concatenate the acceleration and label DataFrames\n",
    "        result_df = pd.concat([acceleration_df, label_df], axis=1)\n",
    "        \n",
    "        # Append the result DataFrame to the main DataFrame\n",
    "        df = pd.concat([df, result_df], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "df = pd.DataFrame(columns=['Acceleration', 'Label'])\n",
    "folder_path = '/'\n",
    "\n",
    "# Provide the CSV file path and label value\n",
    "# Define label mappings\n",
    "label_mappings = {\n",
    "    'Helthy': 0,\n",
    "    'Suffling': 1\n",
    "}\n",
    "csv_files = glob.glob( '*.csv')\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    # Extract the label from the file name\n",
    "    file_name = csv_file.split('/')[-1]  # Extract file name from the path\n",
    "    label = None\n",
    "    for key in label_mappings.keys():\n",
    "        if key.lower() in file_name.lower():\n",
    "            label = label_mappings[key]\n",
    "            break\n",
    "    \n",
    "    # If label is not found in the mappings, skip the file\n",
    "    if label is None:\n",
    "        continue\n",
    "    \n",
    "    # Append the acceleration data and label to the DataFrame\n",
    "    df = append_acceleration_data(csv_file, label, df)\n",
    "\n",
    "# Display the resulting DataFram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b721d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Helthy_ahsan.csv',\n",
       " 'Helthy_ahsan_0.csv',\n",
       " 'Helthy_mazar.csv',\n",
       " 'Suffling_ahsan.csv',\n",
       " 'Suffling_ahsan_0.csv',\n",
       " 'Suffling_mazar.csv']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "68dbe3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 14ms/step - loss: 0.8167 - accuracy: 0.5529\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3202 - accuracy: 0.8824\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1492 - accuracy: 0.9529\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0878 - accuracy: 0.9529\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0657 - accuracy: 0.9647\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0542 - accuracy: 0.9647\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0460 - accuracy: 0.9882\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0408 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0360 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0326 - accuracy: 1.0000\n",
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.6818181872367859\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Split the DataFrame into features (acceleration data) and labels\n",
    "X = np.array(df['Acceleration'].tolist())\n",
    "y = np.array(df['Label'].tolist())\n",
    "\n",
    "# Preprocess the acceleration data if required\n",
    "# ...\n",
    "\n",
    "# Perform label encoding if labels are not numerical\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the feature data for CNN input\n",
    "X_train = X_train.reshape(X_train.shape[0], 3, 250, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 3, 250, 1)\n",
    "\n",
    "# Convert the labels to categorical format\n",
    "num_classes = len(np.unique(y))\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(3, 200), activation='relu', input_shape=(3, 250, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1)\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_loss, train_accuracy = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train accuracy:', train_accuracy)\n",
    "\n",
    "# Evaluate the model on testing data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test accuracy:', test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e144eaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "3/3 [==============================] - 3s 9ms/step - loss: 0.7018 - accuracy: 0.5529\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5122 - accuracy: 0.7529\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4089 - accuracy: 0.9412\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3345 - accuracy: 0.9882\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2751 - accuracy: 0.9882\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2280 - accuracy: 0.9882\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1887 - accuracy: 0.9882\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1561 - accuracy: 0.9882\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1301 - accuracy: 0.9882\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1079 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0902 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0753 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0633 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0533 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0455 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0388 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0336 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0291 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0252 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0221 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0193 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0172 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0153 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.5909090638160706\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Split the DataFrame into features (acceleration data) and labels\n",
    "X = np.array(df['Acceleration'].tolist())\n",
    "y = np.array(df['Label'].tolist())\n",
    "\n",
    "# Preprocess the acceleration data if required\n",
    "# ...\n",
    "\n",
    "# Perform label encoding if labels are not numerical\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the feature data for LSTM input\n",
    "X_train = X_train.reshape(X_train.shape[0], 3, 250)\n",
    "X_test = X_test.reshape(X_test.shape[0], 3, 250)\n",
    "\n",
    "# Convert the labels to categorical format\n",
    "num_classes = len(np.unique(y))\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(3, 250)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=30, verbose=1)\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_loss, train_accuracy = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train accuracy:', train_accuracy)\n",
    "\n",
    "# Evaluate the model on testing data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test accuracy:', test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6040ab4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
